{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit"
  },
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from os.path import basename, isfile, join, splitext\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "from insightface_func.face_detect_crop_single import Face_detect_crop\n",
    "from models.models import create_model\n",
    "from options.test_options import TestOptions\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "from os.path import basename, exists, isfile, join, splitext\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "from util.videoswap import lower_resolution, extract_audio, get_frames_n, _totensor\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from face_seg.nets.MobileNetV2_unet import MobileNetV2_unet\n",
    "\n",
    "seg_model = MobileNetV2_unet(None).to('cuda')\n",
    "state_dict = torch.load('face_seg/checkpoints/model.pt', map_location='cpu')\n",
    "seg_model.load_state_dict(state_dict)\n",
    "seg_model.eval();\n",
    "\n",
    "model, app = None, None\n",
    "transformer_Arcface = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "opt = TestOptions()\n",
    "opt.initialize()\n",
    "opt.parser.add_argument('-f')  # dummy arg to avoid bug\n",
    "opt = opt.parse()\n",
    "opt.Arc_path = './weights/arcface_checkpoint.tar'\n",
    "opt.isTrain = False\n",
    "torch.nn.Module.dump_patches = True\n",
    "global model\n",
    "model = create_model(opt)\n",
    "model.eval()\n",
    "global app\n",
    "app = Face_detect_crop(name='antelope', root='./insightface_func/models')\n",
    "app.prepare(ctx_id=0, det_thresh=0.6, det_size=(256, 256))\n",
    "\n",
    "source = '../reference_videos/gen_0.jpg'\n",
    "target = '../reference_videos/stocks/man_2.mp4'\n",
    "result_dir='./output'\n",
    "crop_size=224\n",
    "\n",
    "\n",
    "assert isfile(source), f'Can\\'t find source at {source}'\n",
    "assert isfile(target), f'Can\\'t find target at {target}'\n",
    "output_filename = f'infer-{splitext(basename(source))[0]}-{splitext(basename(target))[0]}.mp4'\n",
    "output_path = join(result_dir, output_filename)\n",
    "\n",
    "assert model is not None\n",
    "assert app is not None\n",
    "\n",
    "img_a_whole = cv2.imread(source)\n",
    "img_a_align_crop, _ = app.get(img_a_whole, crop_size)\n",
    "img_a_align_crop_pil = Image.fromarray(\n",
    "    cv2.cvtColor(img_a_align_crop[0], cv2.COLOR_BGR2RGB))\n",
    "img_a = transformer_Arcface(img_a_align_crop_pil)\n",
    "img_id = img_a.view(-1, img_a.shape[0], img_a.shape[1], img_a.shape[2])\n",
    "img_id = img_id.cuda()\n",
    "\n",
    "img_id_downsample = F.interpolate(img_id, scale_factor=0.5)\n",
    "latend_id = model.netArc(img_id_downsample)\n",
    "latend_id = latend_id.detach().to('cpu')\n",
    "latend_id = latend_id / np.linalg.norm(latend_id, axis=1, keepdims=True)\n",
    "latend_id = latend_id.to('cuda')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import torchvision.transforms as transforms\n",
    "from fsr.models.SRGAN_model import SRGANModel\n",
    "import easydict\n",
    "\n",
    "esrgan_fsr_transform = transforms.Compose([transforms.Resize((128, 128)),\n",
    "                                 transforms.Normalize(mean=[0.5, 0.5, 0.5],\n",
    "                                                      std=[0.5, 0.5, 0.5])])\n",
    "\n",
    "args = easydict.EasyDict({\n",
    "    'gpu_ids': None,\n",
    "    'batch_size': 32,\n",
    "    'lr_G': 1e-4,\n",
    "    'weight_decay_G': 0,\n",
    "    'beta1_G': 0.9,\n",
    "    'beta2_G': 0.99,\n",
    "    'lr_D': 1e-4,\n",
    "    'weight_decay_D': 0,\n",
    "    'beta1_D': 0.9,\n",
    "    'beta2_D': 0.99,\n",
    "    'lr_scheme': 'MultiStepLR',\n",
    "    'niter': 100000,\n",
    "    'warmup_iter': -1,\n",
    "    'lr_steps': [50000],\n",
    "    'lr_gamma': 0.5,\n",
    "    'pixel_criterion': 'l1',\n",
    "    'pixel_weight': 1e-2,\n",
    "    'feature_criterion': 'l1',\n",
    "    'feature_weight': 1,\n",
    "    'gan_type': 'ragan',\n",
    "    'gan_weight': 5e-3,\n",
    "    'D_update_ratio': 1,\n",
    "    'D_init_iters': 0,\n",
    "\n",
    "    'print_freq': 100,\n",
    "    'val_freq': 1000,\n",
    "    'save_freq': 10000,\n",
    "    'crop_size': 0.85,\n",
    "    'lr_size': 128,\n",
    "    'hr_size': 512,\n",
    "\n",
    "    # network G\n",
    "    'which_model_G': 'RRDBNet',\n",
    "    'G_in_nc': 3,\n",
    "    'out_nc': 3,\n",
    "    'G_nf': 64,\n",
    "    'nb': 16,\n",
    "\n",
    "    # network D\n",
    "    'which_model_D': 'discriminator_vgg_128',\n",
    "    'D_in_nc': 3,\n",
    "    'D_nf': 64,\n",
    "\n",
    "    # data dir\n",
    "    'pretrain_model_G': 'weights/90000_G.pth',\n",
    "    'pretrain_model_D': None\n",
    "})\n",
    "\n",
    "\n",
    "esrgan_fsr_model = SRGANModel(args, is_train=False)\n",
    "esrgan_fsr_model.load()\n",
    "esrgan_fsr_model.netG.to('cuda')\n",
    "esrgan_fsr_model.netG.eval();\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import expit\n",
    "from torchvision.transforms.functional import normalize\n",
    "\n",
    "\n",
    "def reverse2wholeimage(swaped_imgs, mats, crop_size, oriimg, save_path=''):\n",
    "    target_image_list = []\n",
    "    img_mask_list = []\n",
    "    for swaped_img, mat in zip(swaped_imgs, mats):\n",
    "        # https://github.com/kampta/face-seg\n",
    "        seg_mask_logits = seg_model(swaped_img.unsqueeze(0))\n",
    "        seg_mask = seg_mask_logits.squeeze().cpu().detach().numpy().transpose((1, 2, 0))\n",
    "        img_mask = np.argmax(seg_mask, axis=2) == 1\n",
    "        img_mask = np.array(img_mask * 255, dtype=float)\n",
    "        # img_mask = np.full((crop_size, crop_size), 255, dtype=float)\n",
    "\n",
    "        sigm_ = expit(seg_mask[:, :, 1])\n",
    "        \n",
    "        ###\n",
    "        fig, axs = plt.subplots(1, 5, figsize=(30, 30))\n",
    "        axs.flat[0].imshow(sigm_); axs.flat[0].set_xlabel('as is')\n",
    "        axs.flat[1].imshow(sigm_ > 0.5); axs.flat[1].set_xlabel('> 0.5')\n",
    "        axs.flat[2].imshow(sigm_ > 0.6); axs.flat[2].set_xlabel('> 0.6')\n",
    "        axs.flat[3].imshow(sigm_ > 0.7); axs.flat[3].set_xlabel('> 0.7')\n",
    "        axs.flat[4].imshow(sigm_ > 0.8); axs.flat[4].set_xlabel('> 0.8')\n",
    "        plt.show()\n",
    "        ###\n",
    "\n",
    "        # SR-ESRGAN_fsr https://github.com/ewrfcas/Face-Super-Resolution\n",
    "        swaped_img = esrgan_fsr_transform(torch.clone(swaped_img))\n",
    "        swaped_img = esrgan_fsr_model.netG(swaped_img.unsqueeze(0))\n",
    "        swaped_img = swaped_img.squeeze(0).cpu().detach().numpy().transpose((1, 2, 0))\n",
    "        swaped_img = swaped_img / 2.0 + 0.5\n",
    "\n",
    "        cv2.imwrite(splitext(save_path)[0] + '_' + splitext(save_path)[1], cv2.cvtColor(swaped_img * 255, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "        mat_rev = cv2.invertAffineTransform(mat)\n",
    "        mat_rev_face = np.array(mat_rev)\n",
    "        mat_rev_face[:2, :2] = mat_rev_face[:2, :2] / (swaped_img.shape[0] / crop_size)\n",
    "\n",
    "        orisize = (oriimg.shape[1], oriimg.shape[0])\n",
    "        target_image = cv2.warpAffine(swaped_img, mat_rev_face, orisize)\n",
    "        img_mask = cv2.warpAffine(img_mask, mat_rev, orisize)\n",
    "\n",
    "        ###\n",
    "        fig, axs = plt.subplots(1, 5, figsize=(30, 30))\n",
    "        img_mask_ = np.array(img_mask)\n",
    "        axs.flat[0].imshow(img_mask_[500:1500]); axs.flat[0].set_xlabel('as is')\n",
    "        img_mask_ = np.array(img_mask); img_mask_[img_mask_ > 1] = 255\n",
    "        axs.flat[1].imshow(img_mask_[500:1500]); axs.flat[1].set_xlabel('> 1')\n",
    "        img_mask_ = np.array(img_mask); img_mask_[img_mask_ > 5] = 255\n",
    "        axs.flat[2].imshow(img_mask_[500:1500]); axs.flat[2].set_xlabel('> 5')\n",
    "        img_mask_ = np.array(img_mask); img_mask_[img_mask_ > 10] = 255\n",
    "        axs.flat[3].imshow(img_mask_[500:1500]); axs.flat[3].set_xlabel('> 10')\n",
    "        img_mask_ = np.array(img_mask); img_mask_[img_mask_ > 20] = 255\n",
    "        axs.flat[4].imshow(img_mask_[500:1500]); axs.flat[4].set_xlabel('> 20')\n",
    "        plt.show()\n",
    "        ###\n",
    "\n",
    "        ###\n",
    "        fig, axs = plt.subplots(3, 5, figsize=(50, 30)); \n",
    "        img_mask_ = np.array(img_mask) / 255;\n",
    "        img_mask_ = np.reshape(img_mask_, [img_mask_.shape[0], img_mask_.shape[1], 1])\n",
    "        target_image_ = np.array(target_image, dtype=np.float64)[..., ::-1] * 255\n",
    "        img = img_mask_ * target_image_ + (1-img_mask_) * np.array(oriimg, dtype=np.float64)\n",
    "        axs[0][0].imshow(cv2.cvtColor(img.astype(np.uint8), cv2.COLOR_BGR2RGB)[500:1500]); axs[0][0].set_xlabel('as is')\n",
    "\n",
    "        img_mask_ = np.array(img_mask);\n",
    "        kernel = np.ones((10, 10), np.uint8)\n",
    "        img_mask_ = cv2.erode(img_mask_, kernel, iterations=1) / 255\n",
    "        img_mask_ = np.reshape(img_mask_, [img_mask_.shape[0], img_mask_.shape[1], 1])\n",
    "        target_image_ = np.array(target_image, dtype=np.float64)[..., ::-1] * 255\n",
    "        img = img_mask_ * target_image_ + (1-img_mask_) * np.array(oriimg, dtype=np.float64)\n",
    "        axs[0][1].imshow(cv2.cvtColor(img.astype(np.uint8), cv2.COLOR_BGR2RGB)[500:1500]); axs[0][1].set_xlabel('k10x10_1')\n",
    "        img_mask_ = np.array(img_mask);\n",
    "        kernel = np.ones((10, 10), np.uint8)\n",
    "        img_mask_ = cv2.erode(img_mask_, kernel, iterations=2) / 255\n",
    "        img_mask_ = np.reshape(img_mask_, [img_mask_.shape[0], img_mask_.shape[1], 1])\n",
    "        target_image_ = np.array(target_image, dtype=np.float64)[..., ::-1] * 255\n",
    "        img = img_mask_ * target_image_ + (1-img_mask_) * np.array(oriimg, dtype=np.float64)\n",
    "        axs[1][1].imshow(cv2.cvtColor(img.astype(np.uint8), cv2.COLOR_BGR2RGB)[500:1500]); axs[1][1].set_xlabel('k10x10_2')\n",
    "        img_mask_ = np.array(img_mask);\n",
    "        kernel = np.ones((10, 10), np.uint8)\n",
    "        img_mask_ = cv2.erode(img_mask_, kernel, iterations=3) / 255\n",
    "        img_mask_ = np.reshape(img_mask_, [img_mask_.shape[0], img_mask_.shape[1], 1])\n",
    "        target_image_ = np.array(target_image, dtype=np.float64)[..., ::-1] * 255\n",
    "        img = img_mask_ * target_image_ + (1-img_mask_) * np.array(oriimg, dtype=np.float64)\n",
    "        axs[2][1].imshow(cv2.cvtColor(img.astype(np.uint8), cv2.COLOR_BGR2RGB)[500:1500]); axs[2][1].set_xlabel('k10x10_3')\n",
    "\n",
    "\n",
    "        img_mask_ = np.array(img_mask);\n",
    "        kernel = np.ones((15, 15), np.uint8)\n",
    "        img_mask_ = cv2.erode(img_mask_, kernel, iterations=1) / 255\n",
    "        img_mask_ = np.reshape(img_mask_, [img_mask_.shape[0], img_mask_.shape[1], 1])\n",
    "        target_image_ = np.array(target_image, dtype=np.float64)[..., ::-1] * 255\n",
    "        img = img_mask_ * target_image_ + (1-img_mask_) * np.array(oriimg, dtype=np.float64)\n",
    "        axs[0][2].imshow(cv2.cvtColor(img.astype(np.uint8), cv2.COLOR_BGR2RGB)[500:1500]); axs[0][2].set_xlabel('k15x15')\n",
    "        img_mask_ = np.array(img_mask);\n",
    "        kernel = np.ones((15, 15), np.uint8)\n",
    "        img_mask_ = cv2.erode(img_mask_, kernel, iterations=2) / 255\n",
    "        img_mask_ = np.reshape(img_mask_, [img_mask_.shape[0], img_mask_.shape[1], 1])\n",
    "        target_image_ = np.array(target_image, dtype=np.float64)[..., ::-1] * 255\n",
    "        img = img_mask_ * target_image_ + (1-img_mask_) * np.array(oriimg, dtype=np.float64)\n",
    "        axs[1][2].imshow(cv2.cvtColor(img.astype(np.uint8), cv2.COLOR_BGR2RGB)[500:1500]); axs[1][2].set_xlabel('k15x15_2')\n",
    "        img_mask_ = np.array(img_mask);\n",
    "        kernel = np.ones((15, 15), np.uint8)\n",
    "        img_mask_ = cv2.erode(img_mask_, kernel, iterations=3) / 255\n",
    "        img_mask_ = np.reshape(img_mask_, [img_mask_.shape[0], img_mask_.shape[1], 1])\n",
    "        target_image_ = np.array(target_image, dtype=np.float64)[..., ::-1] * 255\n",
    "        img = img_mask_ * target_image_ + (1-img_mask_) * np.array(oriimg, dtype=np.float64)\n",
    "        axs[2][2].imshow(cv2.cvtColor(img.astype(np.uint8), cv2.COLOR_BGR2RGB)[500:1500]); axs[2][2].set_xlabel('k15x15_3')\n",
    "\n",
    "\n",
    "        img_mask_ = np.array(img_mask);\n",
    "        kernel = np.ones((20, 20), np.uint8)\n",
    "        img_mask_ = cv2.erode(img_mask_, kernel, iterations=1) / 255\n",
    "        img_mask_ = np.reshape(img_mask_, [img_mask_.shape[0], img_mask_.shape[1], 1])\n",
    "        target_image_ = np.array(target_image, dtype=np.float64)[..., ::-1] * 255\n",
    "        img = img_mask_ * target_image_ + (1-img_mask_) * np.array(oriimg, dtype=np.float64)\n",
    "        axs[0][3].imshow(cv2.cvtColor(img.astype(np.uint8), cv2.COLOR_BGR2RGB)[500:1500]); axs[0][3].set_xlabel('k20x20')\n",
    "        img_mask_ = np.array(img_mask);\n",
    "        kernel = np.ones((20, 20), np.uint8)\n",
    "        img_mask_ = cv2.erode(img_mask_, kernel, iterations=2) / 255\n",
    "        img_mask_ = np.reshape(img_mask_, [img_mask_.shape[0], img_mask_.shape[1], 1])\n",
    "        target_image_ = np.array(target_image, dtype=np.float64)[..., ::-1] * 255\n",
    "        img = img_mask_ * target_image_ + (1-img_mask_) * np.array(oriimg, dtype=np.float64)\n",
    "        axs[1][3].imshow(cv2.cvtColor(img.astype(np.uint8), cv2.COLOR_BGR2RGB)[500:1500]); axs[1][3].set_xlabel('k20x20_2')\n",
    "        img_mask_ = np.array(img_mask);\n",
    "        kernel = np.ones((20, 20), np.uint8)\n",
    "        img_mask_ = cv2.erode(img_mask_, kernel, iterations=3) / 255\n",
    "        img_mask_ = np.reshape(img_mask_, [img_mask_.shape[0], img_mask_.shape[1], 1])\n",
    "        target_image_ = np.array(target_image, dtype=np.float64)[..., ::-1] * 255\n",
    "        img = img_mask_ * target_image_ + (1-img_mask_) * np.array(oriimg, dtype=np.float64)\n",
    "        axs[2][3].imshow(cv2.cvtColor(img.astype(np.uint8), cv2.COLOR_BGR2RGB)[500:1500]); axs[2][3].set_xlabel('k20x20_3')\n",
    "\n",
    "\n",
    "        img_mask_ = np.array(img_mask);\n",
    "        kernel = np.ones((30, 30), np.uint8)\n",
    "        img_mask_ = cv2.erode(img_mask_, kernel, iterations=1) / 255\n",
    "        img_mask_ = np.reshape(img_mask_, [img_mask_.shape[0], img_mask_.shape[1], 1])\n",
    "        target_image_ = np.array(target_image, dtype=np.float64)[..., ::-1] * 255\n",
    "        img = img_mask_ * target_image_ + (1-img_mask_) * np.array(oriimg, dtype=np.float64)\n",
    "        axs[0][4].imshow(cv2.cvtColor(img.astype(np.uint8), cv2.COLOR_BGR2RGB)[500:1500]); axs[0][4].set_xlabel('k30x30')\n",
    "        img_mask_ = np.array(img_mask);\n",
    "        kernel = np.ones((30, 30), np.uint8)\n",
    "        img_mask_ = cv2.erode(img_mask_, kernel, iterations=2) / 255\n",
    "        img_mask_ = np.reshape(img_mask_, [img_mask_.shape[0], img_mask_.shape[1], 1])\n",
    "        target_image_ = np.array(target_image, dtype=np.float64)[..., ::-1] * 255\n",
    "        img = img_mask_ * target_image_ + (1-img_mask_) * np.array(oriimg, dtype=np.float64)\n",
    "        axs[1][4].imshow(cv2.cvtColor(img.astype(np.uint8), cv2.COLOR_BGR2RGB)[500:1500]); axs[1][4].set_xlabel('k30x30_2')\n",
    "        img_mask_ = np.array(img_mask);\n",
    "        kernel = np.ones((30, 30), np.uint8)\n",
    "        img_mask_ = cv2.erode(img_mask_, kernel, iterations=3) / 255\n",
    "        img_mask_ = np.reshape(img_mask_, [img_mask_.shape[0], img_mask_.shape[1], 1])\n",
    "        target_image_ = np.array(target_image, dtype=np.float64)[..., ::-1] * 255\n",
    "        img = img_mask_ * target_image_ + (1-img_mask_) * np.array(oriimg, dtype=np.float64)\n",
    "        axs[2][4].imshow(cv2.cvtColor(img.astype(np.uint8), cv2.COLOR_BGR2RGB)[500:1500]); axs[2][4].set_xlabel('k30x30_3')\n",
    "\n",
    "        plt.show()\n",
    "        ###\n",
    "\n",
    "        ###\n",
    "        fig, axs = plt.subplots(3, 5, figsize=(50, 30)); \n",
    "        img_mask_ = np.array(img_mask) / 255;\n",
    "        img_mask_ = np.reshape(img_mask_, [img_mask_.shape[0], img_mask_.shape[1], 1])\n",
    "        target_image_ = np.array(target_image, dtype=np.float64)[..., ::-1] * 255\n",
    "        img = img_mask_ * target_image_ + (1-img_mask_) * np.array(oriimg, dtype=np.float64)\n",
    "        axs[0][0].imshow(cv2.cvtColor(img.astype(np.uint8), cv2.COLOR_BGR2RGB)[500:1500]); axs[0][0].set_xlabel('as is')\n",
    "\n",
    "        img_mask_ = np.array(img_mask);\n",
    "        kernel = np.ones((10, 10), np.uint8)\n",
    "        img_mask_ = cv2.dilate(img_mask_, kernel, iterations=1) / 255\n",
    "        img_mask_ = np.reshape(img_mask_, [img_mask_.shape[0], img_mask_.shape[1], 1])\n",
    "        target_image_ = np.array(target_image, dtype=np.float64)[..., ::-1] * 255\n",
    "        img = img_mask_ * target_image_ + (1-img_mask_) * np.array(oriimg, dtype=np.float64)\n",
    "        axs[0][1].imshow(cv2.cvtColor(img.astype(np.uint8), cv2.COLOR_BGR2RGB)[500:1500]); axs[0][1].set_xlabel('k10x10_1')\n",
    "        img_mask_ = np.array(img_mask);\n",
    "        kernel = np.ones((10, 10), np.uint8)\n",
    "        img_mask_ = cv2.dilate(img_mask_, kernel, iterations=2) / 255\n",
    "        img_mask_ = np.reshape(img_mask_, [img_mask_.shape[0], img_mask_.shape[1], 1])\n",
    "        target_image_ = np.array(target_image, dtype=np.float64)[..., ::-1] * 255\n",
    "        img = img_mask_ * target_image_ + (1-img_mask_) * np.array(oriimg, dtype=np.float64)\n",
    "        axs[1][1].imshow(cv2.cvtColor(img.astype(np.uint8), cv2.COLOR_BGR2RGB)[500:1500]); axs[1][1].set_xlabel('k10x10_2')\n",
    "        img_mask_ = np.array(img_mask);\n",
    "        kernel = np.ones((10, 10), np.uint8)\n",
    "        img_mask_ = cv2.dilate(img_mask_, kernel, iterations=3) / 255\n",
    "        img_mask_ = np.reshape(img_mask_, [img_mask_.shape[0], img_mask_.shape[1], 1])\n",
    "        target_image_ = np.array(target_image, dtype=np.float64)[..., ::-1] * 255\n",
    "        img = img_mask_ * target_image_ + (1-img_mask_) * np.array(oriimg, dtype=np.float64)\n",
    "        axs[2][1].imshow(cv2.cvtColor(img.astype(np.uint8), cv2.COLOR_BGR2RGB)[500:1500]); axs[2][1].set_xlabel('k10x10_3')\n",
    "\n",
    "\n",
    "        img_mask_ = np.array(img_mask);\n",
    "        kernel = np.ones((15, 15), np.uint8)\n",
    "        img_mask_ = cv2.dilate(img_mask_, kernel, iterations=1) / 255\n",
    "        img_mask_ = np.reshape(img_mask_, [img_mask_.shape[0], img_mask_.shape[1], 1])\n",
    "        target_image_ = np.array(target_image, dtype=np.float64)[..., ::-1] * 255\n",
    "        img = img_mask_ * target_image_ + (1-img_mask_) * np.array(oriimg, dtype=np.float64)\n",
    "        axs[0][2].imshow(cv2.cvtColor(img.astype(np.uint8), cv2.COLOR_BGR2RGB)[500:1500]); axs[0][2].set_xlabel('k15x15')\n",
    "        img_mask_ = np.array(img_mask);\n",
    "        kernel = np.ones((15, 15), np.uint8)\n",
    "        img_mask_ = cv2.dilate(img_mask_, kernel, iterations=2) / 255\n",
    "        img_mask_ = np.reshape(img_mask_, [img_mask_.shape[0], img_mask_.shape[1], 1])\n",
    "        target_image_ = np.array(target_image, dtype=np.float64)[..., ::-1] * 255\n",
    "        img = img_mask_ * target_image_ + (1-img_mask_) * np.array(oriimg, dtype=np.float64)\n",
    "        axs[1][2].imshow(cv2.cvtColor(img.astype(np.uint8), cv2.COLOR_BGR2RGB)[500:1500]); axs[1][2].set_xlabel('k15x15_2')\n",
    "        img_mask_ = np.array(img_mask);\n",
    "        kernel = np.ones((15, 15), np.uint8)\n",
    "        img_mask_ = cv2.dilate(img_mask_, kernel, iterations=3) / 255\n",
    "        img_mask_ = np.reshape(img_mask_, [img_mask_.shape[0], img_mask_.shape[1], 1])\n",
    "        target_image_ = np.array(target_image, dtype=np.float64)[..., ::-1] * 255\n",
    "        img = img_mask_ * target_image_ + (1-img_mask_) * np.array(oriimg, dtype=np.float64)\n",
    "        axs[2][2].imshow(cv2.cvtColor(img.astype(np.uint8), cv2.COLOR_BGR2RGB)[500:1500]); axs[2][2].set_xlabel('k15x15_3')\n",
    "\n",
    "\n",
    "        img_mask_ = np.array(img_mask);\n",
    "        kernel = np.ones((20, 20), np.uint8)\n",
    "        img_mask_ = cv2.dilate(img_mask_, kernel, iterations=1) / 255\n",
    "        img_mask_ = np.reshape(img_mask_, [img_mask_.shape[0], img_mask_.shape[1], 1])\n",
    "        target_image_ = np.array(target_image, dtype=np.float64)[..., ::-1] * 255\n",
    "        img = img_mask_ * target_image_ + (1-img_mask_) * np.array(oriimg, dtype=np.float64)\n",
    "        axs[0][3].imshow(cv2.cvtColor(img.astype(np.uint8), cv2.COLOR_BGR2RGB)[500:1500]); axs[0][3].set_xlabel('k20x20')\n",
    "        img_mask_ = np.array(img_mask);\n",
    "        kernel = np.ones((20, 20), np.uint8)\n",
    "        img_mask_ = cv2.dilate(img_mask_, kernel, iterations=2) / 255\n",
    "        img_mask_ = np.reshape(img_mask_, [img_mask_.shape[0], img_mask_.shape[1], 1])\n",
    "        target_image_ = np.array(target_image, dtype=np.float64)[..., ::-1] * 255\n",
    "        img = img_mask_ * target_image_ + (1-img_mask_) * np.array(oriimg, dtype=np.float64)\n",
    "        axs[1][3].imshow(cv2.cvtColor(img.astype(np.uint8), cv2.COLOR_BGR2RGB)[500:1500]); axs[1][3].set_xlabel('k20x20_2')\n",
    "        img_mask_ = np.array(img_mask);\n",
    "        kernel = np.ones((20, 20), np.uint8)\n",
    "        img_mask_ = cv2.dilate(img_mask_, kernel, iterations=3) / 255\n",
    "        img_mask_ = np.reshape(img_mask_, [img_mask_.shape[0], img_mask_.shape[1], 1])\n",
    "        target_image_ = np.array(target_image, dtype=np.float64)[..., ::-1] * 255\n",
    "        img = img_mask_ * target_image_ + (1-img_mask_) * np.array(oriimg, dtype=np.float64)\n",
    "        axs[2][3].imshow(cv2.cvtColor(img.astype(np.uint8), cv2.COLOR_BGR2RGB)[500:1500]); axs[2][3].set_xlabel('k20x20_3')\n",
    "\n",
    "\n",
    "        img_mask_ = np.array(img_mask);\n",
    "        kernel = np.ones((30, 30), np.uint8)\n",
    "        img_mask_ = cv2.dilate(img_mask_, kernel, iterations=1) / 255\n",
    "        img_mask_ = np.reshape(img_mask_, [img_mask_.shape[0], img_mask_.shape[1], 1])\n",
    "        target_image_ = np.array(target_image, dtype=np.float64)[..., ::-1] * 255\n",
    "        img = img_mask_ * target_image_ + (1-img_mask_) * np.array(oriimg, dtype=np.float64)\n",
    "        axs[0][4].imshow(cv2.cvtColor(img.astype(np.uint8), cv2.COLOR_BGR2RGB)[500:1500]); axs[0][4].set_xlabel('k30x30')\n",
    "        img_mask_ = np.array(img_mask);\n",
    "        kernel = np.ones((30, 30), np.uint8)\n",
    "        img_mask_ = cv2.dilate(img_mask_, kernel, iterations=2) / 255\n",
    "        img_mask_ = np.reshape(img_mask_, [img_mask_.shape[0], img_mask_.shape[1], 1])\n",
    "        target_image_ = np.array(target_image, dtype=np.float64)[..., ::-1] * 255\n",
    "        img = img_mask_ * target_image_ + (1-img_mask_) * np.array(oriimg, dtype=np.float64)\n",
    "        axs[1][4].imshow(cv2.cvtColor(img.astype(np.uint8), cv2.COLOR_BGR2RGB)[500:1500]); axs[1][4].set_xlabel('k30x30_2')\n",
    "        img_mask_ = np.array(img_mask);\n",
    "        kernel = np.ones((30, 30), np.uint8)\n",
    "        img_mask_ = cv2.dilate(img_mask_, kernel, iterations=3) / 255\n",
    "        img_mask_ = np.reshape(img_mask_, [img_mask_.shape[0], img_mask_.shape[1], 1])\n",
    "        target_image_ = np.array(target_image, dtype=np.float64)[..., ::-1] * 255\n",
    "        img = img_mask_ * target_image_ + (1-img_mask_) * np.array(oriimg, dtype=np.float64)\n",
    "        axs[2][4].imshow(cv2.cvtColor(img.astype(np.uint8), cv2.COLOR_BGR2RGB)[500:1500]); axs[2][4].set_xlabel('k30x30_3')\n",
    "\n",
    "        plt.show()\n",
    "        ###\n",
    "\n",
    "\n",
    "\n",
    "        kernel = np.ones((10, 10), np.uint8)\n",
    "        img_mask = cv2.erode(img_mask, kernel, iterations=1) / 255\n",
    "        img_mask = np.reshape(img_mask, [img_mask.shape[0], img_mask.shape[1], 1])\n",
    "        target_image = np.array(target_image, dtype=np.float64)[..., ::-1] * 255\n",
    "        img_mask_list.append(img_mask)\n",
    "        target_image_list.append(target_image)\n",
    "\n",
    "    img = np.array(oriimg, dtype=np.float64)\n",
    "    for img_mask, target_image in zip(img_mask_list, target_image_list):\n",
    "        img = img_mask * target_image + (1-img_mask) * img\n",
    "\n",
    "    final_img = img.astype(np.uint8)\n",
    "    # plt.imshow(cv2.cvtColor(final_img, cv2.COLOR_BGR2RGB)); plt.show(); print('final_img-RGB') ###\n",
    "\n",
    "    cv2.imwrite(save_path, final_img)\n",
    "\n",
    "\n",
    "video_path = target\n",
    "temp_results_dir='./temp_results'\n",
    "swap_model = model\n",
    "detect_model = app\n",
    "id_veсtor = latend_id\n",
    "\n",
    "lower_resolution(video_path)\n",
    "print(f'=> Swapping face in \"{video_path}\"...')\n",
    "if exists(temp_results_dir):\n",
    "    shutil.rmtree(temp_results_dir)\n",
    "os.makedirs(temp_results_dir)\n",
    "\n",
    "audio_path = join(temp_results_dir, splitext(basename(video_path))[0] + '.wav')\n",
    "extract_audio(video_path, audio_path)\n",
    "\n",
    "frame_count = get_frames_n(video_path)\n",
    "\n",
    "video = cv2.VideoCapture(video_path)\n",
    "fps = video.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "for i, frame_index in tqdm(enumerate(range(frame_count))): \n",
    "    if i > 0:\n",
    "        break\n",
    "    _, frame = video.read()\n",
    "    detect_results = detect_model.get(frame, crop_size)     \n",
    "\n",
    "    if detect_results is not None:\n",
    "        frame_align_crop_list = detect_results[0]\n",
    "        frame_mat_list = detect_results[1]\n",
    "        swap_result_list = []\n",
    "\n",
    "        for frame_align_crop in frame_align_crop_list:\n",
    "            frame_align_crop_tensor = _totensor(cv2.cvtColor(frame_align_crop,cv2.COLOR_BGR2RGB))[None,...].cuda()\n",
    "\n",
    "            swap_result = swap_model(None, frame_align_crop_tensor, id_veсtor, None, True)[0]\n",
    "            swap_result_list.append(swap_result)\n",
    "        reverse2wholeimage(swap_result_list, frame_mat_list, crop_size, frame, join(temp_results_dir, 'frame_{:0>7d}.jpg'.format(frame_index)))\n",
    "    else:\n",
    "        frame = frame.astype(np.uint8)\n",
    "        cv2.imwrite(join(temp_results_dir, 'frame_{:0>7d}.jpg'.format(frame_index)), frame)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ]
}