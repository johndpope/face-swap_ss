{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit"
  },
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from os.path import basename, isfile, join, splitext\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "from insightface_func.face_detect_crop_single import Face_detect_crop\n",
    "from models.models import create_model\n",
    "from options.test_options import TestOptions\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "from os.path import basename, exists, isfile, join, splitext\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "from util.videoswap import lower_resolution, extract_audio, get_frames_n, _totensor\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from face_seg.nets.MobileNetV2_unet import MobileNetV2_unet\n",
    "\n",
    "seg_model = MobileNetV2_unet(None).to('cuda')\n",
    "state_dict = torch.load('face_seg/checkpoints/model.pt', map_location='cpu')\n",
    "seg_model.load_state_dict(state_dict)\n",
    "seg_model.eval();\n",
    "\n",
    "model, app = None, None\n",
    "transformer_Arcface = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "opt = TestOptions()\n",
    "opt.initialize()\n",
    "opt.parser.add_argument('-f')  # dummy arg to avoid bug\n",
    "opt = opt.parse()\n",
    "opt.Arc_path = './weights/arcface_checkpoint.tar'\n",
    "opt.isTrain = False\n",
    "torch.nn.Module.dump_patches = True\n",
    "global model\n",
    "model = create_model(opt)\n",
    "model.eval()\n",
    "global app\n",
    "app = Face_detect_crop(name='antelope', root='./insightface_func/models')\n",
    "app.prepare(ctx_id=0, det_thresh=0.6, det_size=(256, 256))\n",
    "\n",
    "source = '../reference_videos/gen_0.jpg'\n",
    "target = '../reference_videos/stocks/man_2.mp4'\n",
    "# source = 'IMG_1237.JPG'\n",
    "# target = 'IMG_1222.MOV'\n",
    "result_dir='./output'\n",
    "crop_size=224\n",
    "\n",
    "\n",
    "assert isfile(source), f'Can\\'t find source at {source}'\n",
    "assert isfile(target), f'Can\\'t find target at {target}'\n",
    "output_filename = f'infer-{splitext(basename(source))[0]}-{splitext(basename(target))[0]}.mp4'\n",
    "output_path = join(result_dir, output_filename)\n",
    "\n",
    "assert model is not None\n",
    "assert app is not None\n",
    "\n",
    "img_a_whole = cv2.imread(source)\n",
    "img_a_align_crop, _ = app.get(img_a_whole, crop_size)\n",
    "img_a_align_crop_pil = Image.fromarray(\n",
    "    cv2.cvtColor(img_a_align_crop[0], cv2.COLOR_BGR2RGB))\n",
    "img_a = transformer_Arcface(img_a_align_crop_pil)\n",
    "img_id = img_a.view(-1, img_a.shape[0], img_a.shape[1], img_a.shape[2])\n",
    "img_id = img_id.cuda()\n",
    "\n",
    "img_id_downsample = F.interpolate(img_id, scale_factor=0.5)\n",
    "latend_id = model.netArc(img_id_downsample)\n",
    "latend_id = latend_id.detach().to('cpu')\n",
    "latend_id = latend_id / np.linalg.norm(latend_id, axis=1, keepdims=True)\n",
    "latend_id = latend_id.to('cuda')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import torchvision.transforms as transforms\n",
    "from fsr.models.SRGAN_model import SRGANModel\n",
    "import easydict\n",
    "\n",
    "esrgan_fsr_transform = transforms.Compose([transforms.Resize((128, 128)),\n",
    "                                 transforms.Normalize(mean=[0.5, 0.5, 0.5],\n",
    "                                                      std=[0.5, 0.5, 0.5])])\n",
    "\n",
    "args = easydict.EasyDict({\n",
    "    'gpu_ids': None,\n",
    "    'batch_size': 32,\n",
    "    'lr_G': 1e-4,\n",
    "    'weight_decay_G': 0,\n",
    "    'beta1_G': 0.9,\n",
    "    'beta2_G': 0.99,\n",
    "    'lr_D': 1e-4,\n",
    "    'weight_decay_D': 0,\n",
    "    'beta1_D': 0.9,\n",
    "    'beta2_D': 0.99,\n",
    "    'lr_scheme': 'MultiStepLR',\n",
    "    'niter': 100000,\n",
    "    'warmup_iter': -1,\n",
    "    'lr_steps': [50000],\n",
    "    'lr_gamma': 0.5,\n",
    "    'pixel_criterion': 'l1',\n",
    "    'pixel_weight': 1e-2,\n",
    "    'feature_criterion': 'l1',\n",
    "    'feature_weight': 1,\n",
    "    'gan_type': 'ragan',\n",
    "    'gan_weight': 5e-3,\n",
    "    'D_update_ratio': 1,\n",
    "    'D_init_iters': 0,\n",
    "\n",
    "    'print_freq': 100,\n",
    "    'val_freq': 1000,\n",
    "    'save_freq': 10000,\n",
    "    'crop_size': 0.85,\n",
    "    'lr_size': 128,\n",
    "    'hr_size': 512,\n",
    "\n",
    "    # network G\n",
    "    'which_model_G': 'RRDBNet',\n",
    "    'G_in_nc': 3,\n",
    "    'out_nc': 3,\n",
    "    'G_nf': 64,\n",
    "    'nb': 16,\n",
    "\n",
    "    # network D\n",
    "    'which_model_D': 'discriminator_vgg_128',\n",
    "    'D_in_nc': 3,\n",
    "    'D_nf': 64,\n",
    "\n",
    "    # data dir\n",
    "    'pretrain_model_G': 'weights/90000_G.pth',\n",
    "    'pretrain_model_D': None\n",
    "})\n",
    "\n",
    "\n",
    "esrgan_fsr_model = SRGANModel(args, is_train=False)\n",
    "esrgan_fsr_model.load()\n",
    "esrgan_fsr_model.netG.to('cuda')\n",
    "esrgan_fsr_model.netG.eval();"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import expit\n",
    "from torchvision.transforms.functional import normalize\n",
    "\n",
    "\n",
    "def reverse2wholeimage(swaped_imgs, mats, crop_size, oriimg, save_path=''):\n",
    "    target_image_list = []\n",
    "    img_mask_list = []\n",
    "    for swaped_img, mat in zip(swaped_imgs, mats):\n",
    "        print('swaped_img:'); plt.imshow(swaped_img.cpu().detach().numpy().transpose((1, 2, 0))); plt.show() ###        \n",
    "\n",
    "        # https://github.com/kampta/face-seg\n",
    "        seg_mask_logits = seg_model(swaped_img.unsqueeze(0))\n",
    "        seg_mask = seg_mask_logits.squeeze().cpu().detach().numpy().transpose((1, 2, 0))\n",
    "        img_mask = np.argmax(seg_mask, axis=2) == 1\n",
    "        img_mask = np.array(img_mask * 255, dtype=float)\n",
    "        # img_mask = np.full((crop_size, crop_size), 255, dtype=float)\n",
    "\n",
    "        # select and fill the biggest contour\n",
    "        contours, _ = cv2.findContours(img_mask.astype(np.uint8), cv2.RETR_CCOMP, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        img_mask_ = np.zeros_like(img_mask)\n",
    "        cv2.drawContours(img_mask_, [max(contours, key = cv2.contourArea)], 0, 255, -1)\n",
    "        img_mask = np.array(img_mask_)\n",
    "        \n",
    "        # SR-ESRGAN_fsr https://github.com/ewrfcas/Face-Super-Resolution\n",
    "        swaped_img = esrgan_fsr_transform(torch.clone(swaped_img))\n",
    "        swaped_img = esrgan_fsr_model.netG(swaped_img.unsqueeze(0))\n",
    "        swaped_img = swaped_img.squeeze(0).cpu().detach().numpy().transpose((1, 2, 0))\n",
    "        swaped_img = np.clip(swaped_img / 2.0 + 0.5, 0, 1)\n",
    "\n",
    "        # cv2.imwrite(splitext(save_path)[0] + '_' + splitext(save_path)[1], cv2.cvtColor(swaped_img * 255, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "        # revert transformation\n",
    "        mat_rev = cv2.invertAffineTransform(mat)\n",
    "        mat_rev_face = np.array(mat_rev)\n",
    "        mat_rev_face[:2, :2] = mat_rev_face[:2, :2] / (swaped_img.shape[0] / crop_size)\n",
    "        orisize = (oriimg.shape[1], oriimg.shape[0])\n",
    "        target_image = cv2.warpAffine(swaped_img, mat_rev_face, orisize)\n",
    "        target_image = np.array(target_image, dtype=np.float64)[..., ::-1] * 255\n",
    "        # print('target_image:'); plt.imshow(target_image); plt.show() ###\n",
    "        # print(target_image.shape, target_image.min(), target_image.max())\n",
    "\n",
    "        ###\n",
    "        print('face segmentation:')\n",
    "        sigm_ = expit(seg_mask[:, :, 1])\n",
    "        fig, axs = plt.subplots(1, 4, figsize=(30, 30))\n",
    "        axs.flat[0].imshow(sigm_); axs.flat[0].set_xlabel('as is')\n",
    "        sigm_[sigm_ < 0.5] = 0; axs.flat[1].imshow(sigm_); axs.flat[1].set_xlabel('>= 0.5')\n",
    "        sigm_[sigm_ < 0.75] = 0; axs.flat[2].imshow(sigm_); axs.flat[2].set_xlabel('>= 0.75')\n",
    "        sigm_[sigm_ < 0.9] = 0; axs.flat[3].imshow(sigm_); axs.flat[3].set_xlabel('>= 0.9')\n",
    "        plt.show()\n",
    "        ###\n",
    "    \n",
    "        ###\n",
    "        print('hair segmentation:')\n",
    "        sigm_ = expit(seg_mask[:, :, 2])\n",
    "        fig, axs = plt.subplots(1, 4, figsize=(30, 30))\n",
    "        axs.flat[0].imshow(sigm_); axs.flat[0].set_xlabel('as is')\n",
    "        sigm_[sigm_ < 0.5] = 0; axs.flat[1].imshow(sigm_); axs.flat[1].set_xlabel('>= 0.5')\n",
    "        sigm_[sigm_ < 0.75] = 0; axs.flat[2].imshow(sigm_); axs.flat[2].set_xlabel('>= 0.75')\n",
    "        sigm_[sigm_ < 0.9] = 0; axs.flat[3].imshow(sigm_); axs.flat[3].set_xlabel('>= 0.9')\n",
    "        plt.show()\n",
    "        ###\n",
    "\n",
    "        # print('img_mask:'); plt.imshow(img_mask); plt.show() ###\n",
    "        # print(img_mask.shape, img_mask.min(), img_mask.max())\n",
    "\n",
    "        ###\n",
    "        print('median blurring:')\n",
    "        fig, axs = plt.subplots(1, 6, figsize=(30, 30))\n",
    "        axs.flat[0].imshow(img_mask); axs.flat[0].set_xlabel('as is')\n",
    "        axs.flat[1].imshow(cv2.medianBlur(img_mask.astype(np.uint8), 3)); axs.flat[1].set_xlabel('kernel 3')\n",
    "        axs.flat[2].imshow(cv2.medianBlur(img_mask.astype(np.uint8), 7)); axs.flat[2].set_xlabel('kernel 7')\n",
    "        axs.flat[3].imshow(cv2.medianBlur(img_mask.astype(np.uint8), 11)); axs.flat[3].set_xlabel('kernel 11')\n",
    "        axs.flat[4].imshow(cv2.medianBlur(img_mask.astype(np.uint8), 15)); axs.flat[4].set_xlabel('kernel 15')\n",
    "        axs.flat[5].imshow(cv2.medianBlur(img_mask.astype(np.uint8), 21)); axs.flat[5].set_xlabel('kernel 21')\n",
    "        plt.show()\n",
    "        ###\n",
    "\n",
    "        ###\n",
    "        print('dilating after median blurring:')\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (10, 10)) # np.ones((10, 10), np.uint8)\n",
    "        fig, axs = plt.subplots(1, 6, figsize=(30, 30))\n",
    "        axs.flat[0].imshow((cv2.dilate(img_mask, kernel, iterations=3) / 255)); axs.flat[0].set_xlabel('as is')\n",
    "        axs.flat[1].imshow((cv2.dilate(cv2.medianBlur(img_mask.astype(np.uint8), 3), kernel, iterations=3) / 255)); axs.flat[1].set_xlabel('kernel 3')\n",
    "        axs.flat[2].imshow((cv2.dilate(cv2.medianBlur(img_mask.astype(np.uint8), 7), kernel, iterations=3) / 255)); axs.flat[2].set_xlabel('kernel 7')\n",
    "        axs.flat[3].imshow((cv2.dilate(cv2.medianBlur(img_mask.astype(np.uint8), 11), kernel, iterations=3) / 255)); axs.flat[3].set_xlabel('kernel 11')\n",
    "        axs.flat[4].imshow((cv2.dilate(cv2.medianBlur(img_mask.astype(np.uint8), 15), kernel, iterations=3) / 255)); axs.flat[4].set_xlabel('kernel 15')\n",
    "        axs.flat[5].imshow((cv2.dilate(cv2.medianBlur(img_mask.astype(np.uint8), 21), kernel, iterations=3) / 255)); axs.flat[5].set_xlabel('kernel 21')\n",
    "        plt.show()\n",
    "        ###\n",
    "\n",
    "\n",
    "        ###\n",
    "        from skimage.exposure import rescale_intensity\n",
    "        print('smoothing edges:')\n",
    "        fig, axs = plt.subplots(2, 7, figsize=(40, 10))\n",
    "        axs[0][0].imshow(img_mask); axs[0][0].set_xlabel('as is')\n",
    "\n",
    "        blur = cv2.GaussianBlur(img_mask, (3, 3), 0, 0)\n",
    "        axs[0][1].imshow(blur); axs[0][1].set_xlabel('blur 3')\n",
    "        axs[1][1].imshow(rescale_intensity(blur, in_range=(127.5,255), out_range=(0,255))); axs[1][1].set_xlabel('smooth')\n",
    "\n",
    "        blur = cv2.GaussianBlur(img_mask, (7, 7), 0, 0)\n",
    "        axs[0][2].imshow(blur); axs[0][2].set_xlabel('blur 7')\n",
    "        axs[1][2].imshow(rescale_intensity(blur, in_range=(127.5,255), out_range=(0,255))); axs[1][2].set_xlabel('smooth')\n",
    "\n",
    "        blur = cv2.GaussianBlur(img_mask, (11, 11), 0, 0)\n",
    "        axs[0][3].imshow(blur); axs[0][3].set_xlabel('blur 11')\n",
    "        axs[1][3].imshow(rescale_intensity(blur, in_range=(127.5,255), out_range=(0,255))); axs[1][3].set_xlabel('smooth')\n",
    "\n",
    "        blur = cv2.GaussianBlur(img_mask, (15, 15), 0, 0)\n",
    "        axs[0][4].imshow(blur); axs[0][4].set_xlabel('blur 15')\n",
    "        axs[1][4].imshow(rescale_intensity(blur, in_range=(127.5,255), out_range=(0,255))); axs[1][4].set_xlabel('smooth')\n",
    "\n",
    "        blur = cv2.GaussianBlur(img_mask, (21, 21), 0, 0)\n",
    "        axs[0][5].imshow(blur); axs[0][5].set_xlabel('blur 21')\n",
    "        axs[1][5].imshow(rescale_intensity(blur, in_range=(127.5,255), out_range=(0,255))); axs[1][5].set_xlabel('smooth')\n",
    "\n",
    "        blur = cv2.GaussianBlur(img_mask, (35, 35), 0, 0)\n",
    "        axs[0][6].imshow(blur); axs[0][6].set_xlabel('blur 35')\n",
    "        axs[1][6].imshow(rescale_intensity(blur, in_range=(127.5,255), out_range=(0,255))); axs[1][6].set_xlabel('smooth')\n",
    "\n",
    "        plt.show()\n",
    "        ###\n",
    "\n",
    "        # img_mask = cv2.medianBlur(img_mask.astype(np.uint8), 15)\n",
    "        # blur = cv2.GaussianBlur(img_mask, (35, 35), 0, 0)\n",
    "        # img_mask = rescale_intensity(blur, in_range=(127.5,255), out_range=(0,255))\n",
    "\n",
    "        ###\n",
    "        fig, axs = plt.subplots(2, 6, figsize=(40, 10))\n",
    "\n",
    "        kernel = np.ones((10, 10), np.uint8)\n",
    "        img_mask_ = cv2.erode(img_mask, kernel, iterations=1) / 255\n",
    "        img_mask_ = cv2.warpAffine(img_mask_, mat_rev, orisize)\n",
    "        img_mask_ = np.reshape(img_mask_, [img_mask_.shape[0], img_mask_.shape[1], 1])\n",
    "        img_ = img_mask_ * target_image + (1-img_mask_) * np.array(oriimg, dtype=np.float64)\n",
    "        axs[0][0].imshow(img_mask_); axs[0][0].set_xlabel('mask as is')\n",
    "        axs[1][0].imshow(cv2.cvtColor(img_.astype(np.uint8), cv2.COLOR_BGR2RGB)[500:1500]); axs[1][0].set_xlabel('result as is')\n",
    "\n",
    "\n",
    "        kernel = np.ones((10, 10), np.uint8)\n",
    "        img_mask_ = cv2.dilate(img_mask, kernel, iterations=1) / 255\n",
    "        img_mask_ = cv2.warpAffine(img_mask_, mat_rev, orisize)\n",
    "        img_mask_ = np.reshape(img_mask_, [img_mask_.shape[0], img_mask_.shape[1], 1])\n",
    "        img_ = img_mask_ * target_image + (1-img_mask_) * np.array(oriimg, dtype=np.float64)\n",
    "        axs[0][1].imshow(img_mask_); axs[0][1].set_xlabel('mask - dilate 10,1')\n",
    "        axs[1][1].imshow(cv2.cvtColor(img_.astype(np.uint8), cv2.COLOR_BGR2RGB)[500:1500]); axs[1][1].set_xlabel('result - dilate 10,1')\n",
    "\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (10, 10))\n",
    "        img_mask_ = cv2.dilate(img_mask, kernel, iterations=1) / 255\n",
    "        img_mask_ = cv2.warpAffine(img_mask_, mat_rev, orisize)\n",
    "        img_mask_ = np.reshape(img_mask_, [img_mask_.shape[0], img_mask_.shape[1], 1])\n",
    "        img_ = img_mask_ * target_image + (1-img_mask_) * np.array(oriimg, dtype=np.float64)\n",
    "        axs[0][2].imshow(img_mask_); axs[0][2].set_xlabel('mask - EL + dilate 10,1')\n",
    "        axs[1][2].imshow(cv2.cvtColor(img_.astype(np.uint8), cv2.COLOR_BGR2RGB)[500:1500]); axs[1][2].set_xlabel('result - EL + dilate 10,1')\n",
    "\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (10, 10))\n",
    "        img_mask_ = cv2.medianBlur(img_mask.astype(np.uint8), 15)\n",
    "        img_mask_ = cv2.dilate(img_mask_, kernel, iterations=1) / 255\n",
    "        img_mask_ = cv2.warpAffine(img_mask_, mat_rev, orisize)\n",
    "        img_mask_ = np.reshape(img_mask_, [img_mask_.shape[0], img_mask_.shape[1], 1])\n",
    "        img_ = img_mask_ * target_image + (1-img_mask_) * np.array(oriimg, dtype=np.float64)\n",
    "        axs[0][3].imshow(img_mask_); axs[0][3].set_xlabel('mask - EL + MB + dilate 10,1')\n",
    "        axs[1][3].imshow(cv2.cvtColor(img_.astype(np.uint8), cv2.COLOR_BGR2RGB)[500:1500]); axs[1][3].set_xlabel('result - EL + MB + dilate 10,1')\n",
    "\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (10, 10))\n",
    "        img_mask_ = cv2.medianBlur(img_mask.astype(np.uint8), 15)\n",
    "        img_mask_ = cv2.GaussianBlur(img_mask_, (35, 35), 0, 0)\n",
    "        img_mask_ = rescale_intensity(img_mask_, in_range=(127.5,255), out_range=(0,255))\n",
    "        img_mask_ = cv2.dilate(img_mask_, kernel, iterations=1) / 255\n",
    "        print(img_mask_.sum())\n",
    "        img_mask_ = cv2.warpAffine(img_mask_, mat_rev, orisize)\n",
    "        img_mask_ = np.reshape(img_mask_, [img_mask_.shape[0], img_mask_.shape[1], 1])\n",
    "        img_ = img_mask_ * target_image + (1-img_mask_) * np.array(oriimg, dtype=np.float64)\n",
    "        axs[0][4].imshow(img_mask_); axs[0][4].set_xlabel('mask - EL + MB + SM + dilate 10,1')\n",
    "        axs[1][4].imshow(cv2.cvtColor(img_.astype(np.uint8), cv2.COLOR_BGR2RGB)[500:1500]); axs[1][4].set_xlabel('result - EL + MB + SM + dilate 10,1')\n",
    "\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (10, 10))\n",
    "        img_mask_ = cv2.medianBlur(img_mask.astype(np.uint8), 15)\n",
    "        img_mask_ = cv2.dilate(img_mask_, kernel, iterations=1)\n",
    "        img_mask_ = cv2.GaussianBlur(img_mask_, (35, 35), 0, 0)\n",
    "        img_mask_ = rescale_intensity(img_mask_, in_range=(127.5,255), out_range=(0,255))\n",
    "        print(img_mask_.sum() / 255)\n",
    "        img_mask_ = cv2.warpAffine(img_mask_ / 255, mat_rev, orisize)\n",
    "        img_mask_ = np.reshape(img_mask_, [img_mask_.shape[0], img_mask_.shape[1], 1])\n",
    "        img_ = img_mask_ * target_image + (1-img_mask_) * np.array(oriimg, dtype=np.float64)\n",
    "        axs[0][5].imshow(img_mask_); axs[0][5].set_xlabel('mask - EL + MB + dilate 10,1 + SM')\n",
    "        axs[1][5].imshow(cv2.cvtColor(img_.astype(np.uint8), cv2.COLOR_BGR2RGB)[500:1500]); axs[1][5].set_xlabel('result - EL + MB + dilate 10,1 + SM')\n",
    "\n",
    "        plt.show()\n",
    "        ###\n",
    "\n",
    "        # img_mask = cv2.medianBlur(img_mask.astype(np.uint8), 15)\n",
    "        # blur = cv2.GaussianBlur(img_mask, (35, 35), 0, 0)\n",
    "        # img_mask = rescale_intensity(blur, in_range=(127.5,255), out_range=(0,255))\n",
    "\n",
    "        kernel = np.ones((10, 10), np.uint8) # cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (10, 10)) # np.ones((10, 10), np.uint8)\n",
    "        img_mask = cv2.erode(img_mask, kernel, iterations=1) / 255\n",
    "        print('img_mask:'); plt.imshow(img_mask); plt.show() ###\n",
    "        print(img_mask.shape, img_mask.min(), img_mask.max())\n",
    "        img_mask = cv2.warpAffine(img_mask, mat_rev, orisize)\n",
    "        img_mask = np.reshape(img_mask, [img_mask.shape[0], img_mask.shape[1], 1])\n",
    "\n",
    "        # img_mask[target_image[:, :, 0] == 0] = 0\n",
    "        # print('img_mask:'); plt.imshow(img_mask); plt.show() ###\n",
    "        # print(img_mask.min(), img_mask.max())\n",
    "\n",
    "        img_mask_list.append(img_mask)\n",
    "        target_image_list.append(target_image)\n",
    "\n",
    "    img = np.array(oriimg, dtype=np.float64)\n",
    "    for img_mask, target_image in zip(img_mask_list, target_image_list):\n",
    "        img = img_mask * target_image + (1-img_mask) * img\n",
    "\n",
    "    final_img = img.astype(np.uint8)\n",
    "    print('final_img-RGB:'); plt.imshow(cv2.cvtColor(final_img, cv2.COLOR_BGR2RGB)); plt.show() ###\n",
    "\n",
    "    cv2.imwrite(save_path, final_img)\n",
    "\n",
    "\n",
    "video_path = target\n",
    "temp_results_dir='./temp_results'\n",
    "swap_model = model\n",
    "detect_model = app\n",
    "id_veсtor = latend_id\n",
    "\n",
    "lower_resolution(video_path)\n",
    "print(f'=> Swapping face in \"{video_path}\"...')\n",
    "if exists(temp_results_dir):\n",
    "    shutil.rmtree(temp_results_dir)\n",
    "os.makedirs(temp_results_dir)\n",
    "\n",
    "audio_path = join(temp_results_dir, splitext(basename(video_path))[0] + '.wav')\n",
    "extract_audio(video_path, audio_path)\n",
    "\n",
    "frame_count = get_frames_n(video_path)\n",
    "\n",
    "video = cv2.VideoCapture(video_path)\n",
    "fps = video.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "for i, frame_index in tqdm(enumerate(range(frame_count))): \n",
    "    if i != 0:\n",
    "        continue\n",
    "    _, frame = video.read()\n",
    "    detect_results = detect_model.get(frame, crop_size)     \n",
    "\n",
    "    if detect_results is not None:\n",
    "        frame_align_crop_list = detect_results[0]\n",
    "        frame_mat_list = detect_results[1]\n",
    "        swap_result_list = []\n",
    "\n",
    "        for frame_align_crop in frame_align_crop_list:\n",
    "            frame_align_crop_tensor = _totensor(cv2.cvtColor(frame_align_crop,cv2.COLOR_BGR2RGB))[None,...].cuda()\n",
    "\n",
    "            swap_result = swap_model(None, frame_align_crop_tensor, id_veсtor, None, True)[0]\n",
    "            swap_result_list.append(swap_result)\n",
    "        reverse2wholeimage(swap_result_list, frame_mat_list, crop_size, frame, join(temp_results_dir, 'frame_{:0>7d}.jpg'.format(frame_index)))\n",
    "    else:\n",
    "        frame = frame.astype(np.uint8)\n",
    "        cv2.imwrite(join(temp_results_dir, 'frame_{:0>7d}.jpg'.format(frame_index)), frame)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ]
}